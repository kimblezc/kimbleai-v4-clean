# Claude Code Instructions for KimbleAI

This file contains default rules and workflows that Claude should follow when working on this project.

## ⏰ GLOBAL TIMESTAMP FORMATTING (ALWAYS APPLY)

**CRITICAL: Include timestamps in ALL responses unless explicitly told otherwise.**

### Timestamp Format Requirements:
- **Format**: `YYYY:MM:DD:HH:MM:SS` (24-hour time)
- **Example**: `2025:10:23:20:15:30`
- **Include**:
  1. Current execution timestamp
  2. Elapsed time since task started
  3. Time markers for long-running operations

### Where to Apply:
- Start of every response: `[2025:10:23:20:15:30]`
- Before/after long operations: `[20:15:30] Starting build... [20:16:45] Build complete (1m 15s elapsed)`
- Deployment confirmations: `Deployed at [20:17:00] - 2m 30s since start`
- File operations: `File modified at [20:17:15]`
- Error messages: `[20:17:30] Error detected (3m elapsed)`

### Examples:
```
[2025:10:23:20:00:00] Starting task...
[20:01:15] npm run build started...
[20:02:30] Build complete (2m 30s elapsed)
[20:03:00] Deployment initiated (3m total)
```

**Note**: This is a GLOBAL rule - apply automatically to all responses.

---

## 🚀 AUTOMATIC TEST AND DEPLOY (PRIMARY RULE)

**CRITICAL: After completing ANY task, automatically test locally and deploy WITHOUT being asked.**

### Complete Workflow (Execute Automatically)

1. **Test Locally**:
   ```bash
   npm run build
   ```
   - Verify build succeeds with exit code 0
   - Check for errors in build output
   - If build fails, fix issues before proceeding

2. **Bump Version** (choose based on change type):
   ```bash
   # Bug fixes, small tweaks → PATCH
   node scripts/bump-version.js patch

   # New features, improvements → MINOR (most common)
   node scripts/bump-version.js minor

   # Breaking changes → MAJOR
   node scripts/bump-version.js major
   ```

3. **Update Changelog in version.json**:
   - Edit version.json to add brief description of changes
   - Include what was fixed/added/changed

4. **Commit, Push, and Deploy**:
   ```bash
   git add .
   git commit -m "your commit message

chore: Bump to v$(node -p "require('./version.json').version")"
   git push origin master
   vercel --prod --yes
   ```

5. **Verify Deployment on Live Site**:
   - Wait 10-15 seconds for CDN propagation
   - Use WebFetch to check https://www.kimbleai.com
   - Confirm version indicator shows correct version number and git hash
   - Example: "v1.2.0 (5f05079)" should be visible on the page
   - If verification fails, wait 30 seconds and try again
   - Report to user: "✅ Deployed v1.2.0 (5f05079) to www.kimbleai.com - CONFIRMED LIVE"

### When to Execute This Workflow

Execute this complete workflow **WITHOUT being told** after:
- ✅ Fixing bugs
- ✅ Adding features
- ✅ Making improvements
- ✅ Updating documentation that affects functionality
- ✅ Refactoring code
- ✅ Any code changes that should be live on kimbleai.com

**DO NOT WAIT for the user to say "deploy" - just do it automatically!**

## 🤖 PARALLEL AGENT DEPLOYMENT

**IMPORTANT: When tasks can be parallelized, deploy separate agents to accomplish them efficiently.**

###When to Use Multiple Agents

Deploy separate agents in parallel when:
- Multiple independent tasks can be executed simultaneously
- Complex analysis requires different areas of expertise
- Research tasks can be distributed across domains
- Testing multiple approaches in parallel is beneficial

### How to Deploy Agents

```typescript
// Example: Deploy 3 agents in parallel for different tasks
Task 1: "Research latest Next.js 15 performance optimizations"
Task 2: "Analyze current database query performance bottlenecks"
Task 3: "Review security vulnerabilities in dependencies"
```

### Reporting Requirements

After agent completion, **ALWAYS provide a comprehensive report**:
- Summary of each agent's findings
- Actionable recommendations
- Priority ranking of suggestions
- Implementation estimates (time/effort)
- Integration points between agent outputs

## 💡 PROACTIVE RECOMMENDATIONS

**CRITICAL: Continuously provide recommendations for project improvement WITHOUT being asked.**

### When to Provide Recommendations

Proactively suggest improvements during:
- Code reviews (suggest patterns, optimizations)
- Deployments (identify technical debt)
- Bug fixes (recommend preventive measures)
- Feature additions (suggest related enhancements)
- Daily check-ins (propose value-adding opportunities)

### What to Recommend

Focus on opportunities the user may not be aware of:
- **Performance**: Database query optimization, caching strategies, bundle size reduction
- **Security**: Vulnerability patches, authentication improvements, data encryption
- **UX**: Accessibility improvements, loading state enhancements, error messaging
- **DX**: Type safety improvements, test coverage gaps, documentation needs
- **Cost**: API usage optimization, resource allocation efficiency
- **Features**: Adjacent functionality that adds value, integration opportunities
- **Tech Debt**: Refactoring opportunities, deprecated dependencies, code duplication

### Stay Current

- Monitor latest framework updates (Next.js, React, Vercel)
- Track new Supabase features and database best practices
- Review AI/ML advancements relevant to KimbleAI
- Follow security advisories for project dependencies
- Identify emerging tools that could improve workflow

### Example Interaction

**User**: "Fixed the transcription timeout bug"
**Claude**:
"✅ Fixed transcription timeout bug. Deployed v1.3.1 (def4567) to www.kimbleai.com - CONFIRMED LIVE

📊 **Proactive Recommendations** (identified during fix):
1. **Performance** (High Priority): Add Redis caching for transcript results - reduce AssemblyAI API calls by 80%, save ~$200/month
2. **Reliability** (Medium): Implement exponential backoff for API retries - prevent cascading failures
3. **Monitoring** (Low): Add Sentry error tracking for transcription failures - current blind spot in error visibility"

**DO NOT WAIT for the user to ask for recommendations - provide them proactively after every task!**

## 🤖 SPECIALIZED AGENT GENERATION & ARCHIE OPTIMIZATION

**CRITICAL: Generate project-specific agents using the latest and best tools available.**

### When to Generate Specialized Agents

Create custom agents when:
- Project needs continuous monitoring and improvement
- Repetitive tasks can be automated
- Complex analysis requires domain expertise
- Multiple systems need coordination

### Agent Generation Guidelines

**Use Latest Tools and Best Practices:**
- **Claude Sonnet 4**: For complex reasoning and code generation
- **GPT-4o**: For fast, reliable analysis and suggestions
- **Vercel AI SDK**: For streaming responses and tool calling
- **Supabase Realtime**: For live monitoring and updates
- **GitHub Actions**: For automated testing and deployment
- **Sentry/LogRocket**: For error tracking and user monitoring

### Archie Autonomous Agent - Current Status & Improvements

**Location**: `lib/autonomous-agent.ts` (1667 lines)

**✅ What Archie Does Well:**
- Error monitoring via `api_logs` table
- Performance monitoring (slow endpoints)
- Task processing with priority queue
- Code generation using GPT-4
- File modification with backups
- Git deployment with rollback
- Comprehensive logging

**❌ Archie's Issues (from PLANNING.md):**
1. **FIXED**: Generic titles → Now extracts specific titles from descriptions (line 419)
2. **FIXED**: Fake tasks → Skips insight findings, only creates actionable tasks (line 398)
3. **FIXED**: Duplicate detection → Checks description content, not just titles (line 407)
4. **PARTIALLY FIXED**: No visibility → Marks tasks as in_progress but completes instantly

**🔧 Improvements Needed:**

1. **Re-enable Useful Features** (currently disabled at lines 176-181):
   ```typescript
   // These were disabled due to noise, but can be re-enabled with fixes:
   - initializePriorityTasks() // ✅ Already has fixes
   - generateImprovementSuggestions() // ✅ Already has fixes
   - proactiveCodeAnalysis() // ⚠️ Needs better specificity
   ```

2. **Add Progress Logging**:
   - Log sub-steps during task execution
   - Report percentage complete for long tasks
   - Show which file is being analyzed/modified

3. **Project-Specific Intelligence**:
   - Learn from PLANNING.md and PROJECT_GOALS.md
   - Understand 8 project categories (transcription, calendar, gmail, drive, etc.)
   - Prioritize based on actual project goals
   - Track progress against goals

4. **Smarter Task Generation**:
   - **Good Title Format**: "Add Redis caching to /api/transcribe/status endpoint"
   - **Bad Title Format**: "Improvement Suggestion" or "Code Cleanup"
   - Include file paths, specific actions, and expected impact
   - Only create tasks that Archie can actually execute

5. **Better Duplicate Prevention**:
   - Hash task descriptions to detect semantic duplicates
   - Check last 7 days, not just current queue
   - Link findings to tasks to prevent re-creation

### Archie Configuration (ARCHIE_CONFIG.md)

**Enabled Features:**
```typescript
{
  "error_monitoring": true,
  "performance_monitoring": true,
  "task_processing": true,
  "proactive_suggestions": true, // Re-enable with fixes
  "code_generation": true,
  "file_modification": false, // Disabled in serverless
  "git_deployment": false, // Disabled in serverless
  "self_improvement": true // Re-enable with better specificity
}
```

**Task Priority System:**
- P10 (Critical): Security vulnerabilities, production errors
- P9 (High): Performance issues >5s, user-facing bugs
- P8 (Medium): Optimization opportunities, code quality
- P7 (Low): Documentation, cleanup, minor improvements

**Execution Schedule:**
- Every 5 minutes via GitHub Actions cron
- On-demand via API endpoint: POST /api/agent/trigger
- Manual control via: POST /api/agent/pause

### Creating Project-Specific Improvement Agent

When user requests agent generation:

1. **Analyze Current State**:
   - Review PLANNING.md for project structure
   - Check PROJECT_GOALS.md for priorities
   - Examine recent commits for patterns
   - Identify pain points and bottlenecks

2. **Generate Agent Specification**:
   ```typescript
   {
     name: "KimbleAI-Optimizer",
     description: "Specialized agent for KimbleAI improvements",
     capabilities: [
       "Monitor API performance (Gmail, Drive, Calendar)",
       "Optimize database queries (Supabase)",
       "Track API costs (OpenAI, AssemblyAI)",
       "Improve search relevance (vector embeddings)",
       "Detect security issues (OAuth, tokens)"
     ],
     tools: ["Supabase", "OpenAI", "Vercel", "GitHub"],
     schedule: "*/5 * * * *" // Every 5 minutes
   }
   ```

3. **Implement Agent**:
   - Create in `lib/agents/[name].ts`
   - Register in `app/api/agent/[name]/route.ts`
   - Add GitHub Actions workflow
   - Configure database tables
   - Set up monitoring/alerts

4. **Test and Deploy**:
   - Run locally first
   - Verify logging and reporting
   - Enable in production gradually
   - Monitor for false positives

### Example: Generate Archie Improvement Agent

```bash
# User request: "Generate agent for project advice"
# Claude creates:

1. KimbleAI-Advisor Agent
   - Reviews code daily
   - Suggests improvements based on best practices
   - Tracks progress against PROJECT_GOALS.md
   - Provides weekly executive summaries

2. Implementation:
   - Uses Claude Sonnet 4 for analysis
   - Integrates with existing Archie logs
   - Saves recommendations to agent_findings
   - Creates high-priority tasks for critical issues
```

### Example Interaction

**User**: "Fix the transcription bug"
**Claude**:
1. Fixes the bug
2. Runs `npm run build` to test locally
3. Runs `node scripts/bump-version.js patch`
4. Updates version.json changelog
5. Commits: "fix: Transcription bug in speaker detection"
6. Pushes to master
7. Deploys with `vercel --prod --yes`
8. Verifies deployment live on www.kimbleai.com using WebFetch
9. Reports: "✅ Fixed transcription bug. Deployed v1.0.1 (abc1234) to www.kimbleai.com - CONFIRMED LIVE"

## Version Control Workflow

**ALWAYS bump version and deploy after making code changes:**

### When Making Changes
After completing ANY code changes (fixes, features, improvements), automatically follow this workflow:

1. **Bump Version** (choose appropriate level):
   ```bash
   # Bug fixes, small tweaks
   node scripts/bump-version.js patch

   # New features, improvements (most common)
   node scripts/bump-version.js minor

   # Breaking changes, major updates
   node scripts/bump-version.js major
   ```

2. **Commit and Deploy**:
   ```bash
   git add version.json
   git commit -m "chore: Bump version to v$(node -p "require('./version.json').version")"
   git push origin master
   vercel --prod --yes
   ```

3. **Verify Deployment**:
   - Check the version indicator in bottom right corner of www.kimbleai.com
   - Format: `v1.0.0 (abc1234)` where abc1234 is git commit hash
   - Should appear on ALL pages after sign-in

### Version Increment Guidelines
- **PATCH (1.0.X)**: Bug fixes, typos, small UI adjustments, documentation
- **MINOR (1.X.0)**: New features, improvements, new API endpoints (MOST COMMON)
- **MAJOR (X.0.0)**: Breaking changes, complete redesigns, architecture changes

### Version Verification
After deployment, the user should see the updated version number in the bottom right corner of any page on www.kimbleai.com. If the version doesn't update:
1. Wait 30-60 seconds for CDN propagation
2. Hard refresh browser (Ctrl+Shift+R)
3. Check Vercel dashboard for deployment status

## Domain Configuration

**CRITICAL**: Only use these domains:
- ✅ www.kimbleai.com
- ✅ kimbleai.com

**NEVER use these subdomains:**
- ❌ ai.kimbleai.com
- ❌ app.kimbleai.com

All code, documentation, and configuration should reference only the approved domains.

## Deployment Process

### Standard Deployment
```bash
git add .
git commit -m "your commit message"
git push origin master
vercel --prod --yes
```

### Deployment with Version Bump
```bash
# Make your code changes...
# Then:
node scripts/bump-version.js [patch|minor|major]
git add .
git commit -m "your commit message

chore: Bump to v$(node -p "require('./version.json').version")"
git push origin master
vercel --prod --yes
```

## Project-Specific Rules

### Authentication
- Users: zach (zach.kimble@gmail.com) and rebecca (rebecca@kimbleai.com)
- OAuth tokens stored in Supabase `user_tokens` table
- Access tokens expire after 1 hour, use refresh tokens automatically

### Transcription System
- Use AssemblyAI API with key from environment variables
- Database records must be created synchronously before returning response
- Always use `assemblyai_id` for transcript references, not database UUID

### File Structure
- Main page: `app/page.tsx`
- Components: `app/components/`
- API routes: `app/api/`
- Scripts: `scripts/`

### Environment Variables
All environment variables validated pre-build by `scripts/validate-env-whitespace.js`

## Adding Your Own Rules

**LOCATION**: `D:\OneDrive\Documents\kimbleai-v4-clean\.claude.md` (this file)

**TO ADD RULES**:
1. Open this file in any text editor
2. Add a new section with `## Your Section Title`
3. Write your instructions in plain language
4. Save the file
5. Rules take effect immediately in new Claude Code sessions

**EXAMPLE**:
```markdown
## My Custom Rule

Always use TypeScript strict mode and include JSDoc comments for all functions.

### Example
// ✅ Good
/** Calculates the sum of two numbers */
function add(a: number, b: number): number {
  return a + b;
}

// ❌ Bad
function add(a, b) {
  return a + b;
}
```

## 📚 COMPREHENSIVE PLANNING GUIDE

**See PLANNING.md for complete project planning methodology.**

Key principles:
- Use `/plan` command for new features
- Break work into categories (transcription, calendar, agents, etc.)
- Learn from Archie agent (good: self-contained execution, bad: generic titles)
- Test incrementally, don't build everything at once
- Define success criteria before starting

## 💡 CODING BEST PRACTICES (DEFAULT BEHAVIORS)

### Error Handling

**ALWAYS wrap async operations in try-catch:**
```typescript
// ✅ GOOD
async function fetchData() {
  try {
    const result = await api.getData();
    return result;
  } catch (error) {
    console.error('[FETCH-DATA] Error:', error);
    return null;
  }
}

// ❌ BAD
async function fetchData() {
  const result = await api.getData(); // Unhandled rejection!
  return result;
}
```

**Include context in error messages:**
```typescript
// ✅ GOOD
console.error('[TRANSCRIPTION-API] Failed to start transcription:', {
  userId,
  fileSize,
  error: error.message
});

// ❌ BAD
console.error('Error:', error);
```

### TypeScript Best Practices

**Define interfaces for all data structures:**
```typescript
// ✅ GOOD
interface Transcription {
  id: string;
  text: string;
  speakers: number;
  duration: number;
  created_at: string;
}

// ❌ BAD
const transcription: any = { /* ... */ };
```

**Use strict null checks:**
```typescript
// ✅ GOOD
const user = await getUser(userId);
if (!user) {
  return NextResponse.json({ error: 'User not found' }, { status: 404 });
}

// ❌ BAD
const user = await getUser(userId);
return NextResponse.json({ data: user.name }); // Potential crash!
```

### React Best Practices

**Use proper hooks dependencies:**
```typescript
// ✅ GOOD
useEffect(() => {
  loadTranscriptions(userId);
}, [userId]); // Depend on userId

// ❌ BAD
useEffect(() => {
  loadTranscriptions(userId);
}, []); // Missing dependency
```

**Memoize expensive computations:**
```typescript
// ✅ GOOD
const sortedTranscriptions = useMemo(() => {
  return transcriptions.sort((a, b) => a.created_at - b.created_at);
}, [transcriptions]);

// ❌ BAD
const sortedTranscriptions = transcriptions.sort(...); // Sorts on every render!
```

### Database Best Practices

**Always use transactions for multi-step operations:**
```typescript
// ✅ GOOD
const { data, error } = await supabase.rpc('create_project_with_tasks', {
  project_data: { name, description },
  task_data: tasks
});

// ❌ BAD
await supabase.from('projects').insert({ name, description });
await supabase.from('tasks').insert(tasks); // Could fail mid-way!
```

**Create database records synchronously in API routes:**
```typescript
// ✅ GOOD
const { data, error } = await supabase
  .from('transcriptions')
  .insert({ id: jobId, status: 'starting' })
  .select()
  .single();

if (error) throw error;

// NOW start background processing
processTranscription(jobId);

// ❌ BAD
processTranscription(jobId); // Background, race condition!
await supabase.from('transcriptions').insert(...); // Too late!
```

### API Route Best Practices

**Validate inputs early:**
```typescript
// ✅ GOOD
export async function POST(req: Request) {
  const body = await req.json();

  if (!body.userId || !body.fileUrl) {
    return NextResponse.json(
      { error: 'userId and fileUrl required' },
      { status: 400 }
    );
  }

  // Continue with valid data...
}

// ❌ BAD
export async function POST(req: Request) {
  const body = await req.json();
  // Assume data is valid, crash later...
}
```

**Include request context in logs:**
```typescript
// ✅ GOOD
console.log('[TRANSCRIBE-API] Starting transcription:', {
  userId,
  fileSize,
  fileName,
  timestamp: new Date().toISOString()
});

// ❌ BAD
console.log('Starting transcription');
```

### Performance Best Practices

**Lazy load heavy components:**
```typescript
// ✅ GOOD
const HeavyComponent = dynamic(() => import('./HeavyComponent'), {
  loading: () => <Spinner />,
  ssr: false
});

// ❌ BAD
import HeavyComponent from './HeavyComponent'; // Loaded always
```

**Debounce user input:**
```typescript
// ✅ GOOD
const debouncedSearch = useDe bounce((query: string) => {
  searchTranscriptions(query);
}, 300);

// ❌ BAD
<input onChange={(e) => searchTranscriptions(e.target.value)} />
// Searches on every keystroke!
```

### Security Best Practices

**Never expose sensitive data in client-side code:**
```typescript
// ✅ GOOD
// In API route (server-side)
const apiKey = process.env.ASSEMBLYAI_API_KEY;

// ❌ BAD
// In React component (client-side)
const apiKey = process.env.NEXT_PUBLIC_ASSEMBLYAI_API_KEY; // Exposed!
```

**Sanitize user input:**
```typescript
// ✅ GOOD
const sanitized = DOMPurify.sanitize(userInput);

// ❌ BAD
dangerouslySetInnerHTML={{ __html: userInput }} // XSS risk!
```

### Testing Best Practices

**Test critical paths:**
```typescript
// ✅ GOOD
describe('Transcription API', () => {
  it('should create database record before processing', async () => {
    const response = await POST(mockRequest);
    expect(response.status).toBe(200);

    const record = await supabase
      .from('transcriptions')
      .select()
      .eq('job_id', jobId)
      .single();

    expect(record.status).toBe('starting');
  });
});
```

**Test error cases, not just happy path:**
```typescript
// ✅ GOOD
it('should return 400 if userId missing', async () => {
  const response = await POST({ body: { fileUrl: 'test.mp3' } });
  expect(response.status).toBe(400);
});
```

### Git Best Practices

**Write descriptive commit messages:**
```bash
# ✅ GOOD
git commit -m "fix: Create transcription DB record synchronously before processing

Fixes race condition where polling requests couldn't find job record
because background processing started before database insert completed.

Changes:
- Move supabase.insert() before processTranscription() call
- Add error handling for insert failures
- Update tests to verify record exists immediately"

# ❌ BAD
git commit -m "fix bug"
```

**Commit frequently with logical chunks:**
```bash
# ✅ GOOD
git commit -m "feat: Add transcription download button"
git commit -m "feat: Implement download API endpoint"
git commit -m "feat: Add format selector (txt/docx)"

# ❌ BAD
# One giant commit with all changes
```

### Naming Conventions

**Use descriptive, searchable names:**
```typescript
// ✅ GOOD
const MAX_FILE_SIZE_BYTES = 50 * 1024 * 1024; // 50MB
const TRANSCRIPTION_POLL_INTERVAL_MS = 2000;

// ❌ BAD
const max = 50000000;
const interval = 2000;
```

**Follow consistent patterns:**
```typescript
// ✅ GOOD - Consistent verb prefixes
async function getTranscription(id: string)
async function createTranscription(data: TranscriptionData)
async function updateTranscription(id: string, data: Partial<TranscriptionData>)
async function deleteTranscription(id: string)

// ❌ BAD - Inconsistent naming
async function transcription(id: string) // Get? Create?
async function makeTranscription(data)
async function modifyTranscription(id, data)
async function removeTranscription(id)
```

### Documentation Standards

**Document WHY, not WHAT:**
```typescript
// ✅ GOOD
// Create database record synchronously BEFORE starting background processing
// to prevent race condition where polling requests can't find the job record
const { data, error } = await supabase
  .from('transcriptions')
  .insert({ id: jobId, status: 'starting' });

// ❌ BAD
// Insert into database
const { data, error } = await supabase
  .from('transcriptions')
  .insert({ id: jobId, status: 'starting' });
```

**Use JSDoc for functions:**
```typescript
// ✅ GOOD
/**
 * Formats a transcription with speaker labels and timestamps
 * @param transcription - Raw transcription data from AssemblyAI
 * @returns Formatted string with "Speaker N: [HH:MM:SS] text"
 */
function formatTranscription(transcription: Transcription): string {
  // ...
}
```

### Deployment Standards

**Always test locally before deploying:**
```bash
# ✅ GOOD
npm run build  # Test build succeeds
# Manually test the feature
git add .
git commit -m "..."
git push
vercel --prod --yes

# ❌ BAD
git add . && git commit -m "fix" && git push && vercel --prod --yes
# No testing!
```

**Bump version after significant changes:**
```bash
# ✅ GOOD
# After adding new feature
node scripts/bump-version.js minor
# Update changelog in version.json
git add version.json
git commit -m "chore: Bump to v1.2.0"

# ❌ BAD
# Never update version, deploy with no tracking
```

---

## Tips for Effective Rules

1. **Be Specific**: "Use semantic versioning" is better than "use versions"
2. **Include Examples**: Show what you want, not just describe it
3. **Use Checklists**: Break complex workflows into numbered steps
4. **Reference Files**: Point to specific files/functions when relevant
5. **Update Regularly**: Add new rules as patterns emerge in your project

---

**Last Updated**: 2025-10-23
**Version**: 1.1.0
