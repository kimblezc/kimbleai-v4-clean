"""
Embedding Model with Dimension Handling
Generated by Archie - Autonomous Agent

Purpose: Handles embedding generation with automatic PCA compression
Impact: Smaller storage, faster retrieval
Risk Level: LOW
"""

import numpy as np
from typing import List, Optional
from vectorizer import EmbeddingVectorizer


class CompressedEmbeddingModel:
    """Embedding model with automatic PCA compression"""

    def __init__(self, use_compression: bool = True, target_dims: int = 300):
        """
        Initialize embedding model.

        Args:
            use_compression: Whether to use PCA compression (default True)
            target_dims: Target dimensions for compression (default 300)
        """
        self.use_compression = use_compression
        self.vectorizer = EmbeddingVectorizer(target_dimensions=target_dims) if use_compression else None
        self.is_fitted = False

    def generate_embedding(self, text: str) -> np.ndarray:
        """
        Generate embedding for text (placeholder - would use OpenAI in production).

        Args:
            text: Input text

        Returns:
            Embedding vector
        """
        # In production: openai.embeddings.create(model="text-embedding-3-small", input=text)
        # This returns 1536-dimensional vector

        # Placeholder: random vector
        np.random.seed(hash(text) % (2**32))
        return np.random.randn(1536)

    def embed_and_compress(self, texts: List[str], fit: bool = False) -> np.ndarray:
        """
        Generate and optionally compress embeddings for multiple texts.

        Args:
            texts: List of text strings
            fit: Whether to fit PCA on these embeddings (first batch only)

        Returns:
            Embeddings array (possibly compressed)
        """
        # Generate embeddings
        embeddings = np.array([self.generate_embedding(text) for text in texts])

        # Apply compression if enabled
        if self.use_compression and self.vectorizer is not None:
            if fit and not self.is_fitted:
                # Fit PCA on first batch
                embeddings = self.vectorizer.fit_transform(embeddings)
                self.is_fitted = True
            elif self.is_fitted:
                # Transform using existing PCA
                embeddings = self.vectorizer.transform(embeddings)
            # else: PCA not fitted yet, return original

        return embeddings

    def save_model(self, filepath: str) -> None:
        """Save compression model"""
        if self.use_compression and self.vectorizer is not None:
            self.vectorizer.save(filepath)

    def load_model(self, filepath: str) -> None:
        """Load compression model"""
        if self.use_compression and self.vectorizer is not None:
            self.vectorizer.load(filepath)
            self.is_fitted = True

    def get_embedding_info(self) -> dict:
        """Get embedding model information"""
        info = {
            'compression_enabled': self.use_compression,
            'is_fitted': self.is_fitted
        }

        if self.use_compression and self.vectorizer is not None:
            info['original_dimensions'] = self.vectorizer.original_dimensions or 1536
            info['compressed_dimensions'] = self.vectorizer.target_dimensions
            info['compression_ratio'] = (self.vectorizer.original_dimensions or 1536) / self.vectorizer.target_dimensions

        return info


if __name__ == '__main__':
    # Test
    print("Testing compressed embedding model...")

    # Create model with compression
    model = CompressedEmbeddingModel(use_compression=True, target_dims=300)

    # Generate test texts
    texts = [
        "How to optimize database queries",
        "Python programming tutorial",
        "Machine learning best practices",
        "Web development with React",
        "Cloud infrastructure setup"
    ] * 20  # 100 texts total

    print(f"\nGenerating embeddings for {len(texts)} texts...")

    # First batch (fit PCA)
    embeddings = model.embed_and_compress(texts, fit=True)

    print(f"\nEmbedding shape: {embeddings.shape}")
    print(f"Model info: {model.get_embedding_info()}")

    print(f"\nStorage savings:")
    original_size = len(texts) * 1536 * 4  # 1536 dims * 4 bytes (float32)
    compressed_size = len(texts) * 300 * 4
    savings = (1 - compressed_size / original_size) * 100
    print(f"  Original: {original_size / 1024 / 1024:.2f} MB")
    print(f"  Compressed: {compressed_size / 1024 / 1024:.2f} MB")
    print(f"  Savings: {savings:.1f}%")
