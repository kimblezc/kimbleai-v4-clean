"""
Smart Caching for Drive Searches
Generated by Archie - Autonomous Agent

Purpose: Remembers recent searches to avoid hitting Drive API repeatedly
Impact: Faster results, lower API costs
Risk Level: LOW
"""

from datetime import datetime, timedelta
from typing import Any, Optional, Dict
import hashlib
import json


class DriveCachingLayer:
    """Caching layer using cachetools patterns for Drive API responses"""

    def __init__(self, ttl_seconds: int = 300, max_size: int = 100):
        """
        Initialize cache.

        Args:
            ttl_seconds: Time to live in seconds (default 300 = 5 minutes)
            max_size: Maximum number of cached items (default 100)
        """
        self.cache: Dict[str, Dict[str, Any]] = {}
        self.ttl = timedelta(seconds=ttl_seconds)
        self.max_size = max_size
        self.access_times: Dict[str, datetime] = {}

    def _generate_key(self, query: str, folder_id: Optional[str] = None, file_types: Optional[list] = None) -> str:
        """
        Generate cache key from search parameters.

        Args:
            query: Search query
            folder_id: Optional folder to search in
            file_types: Optional list of file types to filter

        Returns:
            Cache key (hash)
        """
        cache_input = {
            'query': query.lower().strip(),
            'folder_id': folder_id,
            'file_types': sorted(file_types) if file_types else []
        }

        json_str = json.dumps(cache_input, sort_keys=True)
        return hashlib.sha256(json_str.encode()).hexdigest()[:16]

    def get(self, query: str, folder_id: Optional[str] = None, file_types: Optional[list] = None) -> Optional[Any]:
        """
        Get cached results.

        Args:
            query: Search query
            folder_id: Optional folder ID
            file_types: Optional file types filter

        Returns:
            Cached results or None
        """
        key = self._generate_key(query, folder_id, file_types)

        if key not in self.cache:
            return None

        cached_item = self.cache[key]

        # Check expiration
        if datetime.now() > cached_item['expires_at']:
            self._remove(key)
            return None

        # Update access time for LRU
        self.access_times[key] = datetime.now()

        return cached_item['data']

    def set(self, query: str, data: Any, folder_id: Optional[str] = None, file_types: Optional[list] = None) -> None:
        """
        Store results in cache.

        Args:
            query: Search query
            data: Results to cache
            folder_id: Optional folder ID
            file_types: Optional file types filter
        """
        key = self._generate_key(query, folder_id, file_types)

        # Evict if cache is full
        if len(self.cache) >= self.max_size and key not in self.cache:
            self._evict_lru()

        self.cache[key] = {
            'data': data,
            'expires_at': datetime.now() + self.ttl,
            'created_at': datetime.now(),
            'query': query
        }
        self.access_times[key] = datetime.now()

    def _remove(self, key: str) -> None:
        """Remove item from cache"""
        if key in self.cache:
            del self.cache[key]
        if key in self.access_times:
            del self.access_times[key]

    def _evict_lru(self) -> None:
        """Evict least recently used item"""
        if not self.access_times:
            return

        # Find oldest access time
        oldest_key = min(self.access_times.items(), key=lambda x: x[1])[0]
        self._remove(oldest_key)

    def clear(self) -> None:
        """Clear all cached items"""
        self.cache = {}
        self.access_times = {}

    def cleanup_expired(self) -> int:
        """
        Remove expired items.

        Returns:
            Number of items removed
        """
        now = datetime.now()
        expired_keys = [
            key for key, item in self.cache.items()
            if now > item['expires_at']
        ]

        for key in expired_keys:
            self._remove(key)

        return len(expired_keys)

    def get_stats(self) -> Dict[str, Any]:
        """Get cache statistics"""
        return {
            'size': len(self.cache),
            'max_size': self.max_size,
            'ttl_seconds': self.ttl.total_seconds(),
            'usage_percentage': (len(self.cache) / self.max_size) * 100 if self.max_size > 0 else 0
        }


if __name__ == '__main__':
    # Test
    print("Testing Drive caching layer...")

    cache = DriveCachingLayer(ttl_seconds=5, max_size=3)

    # Test basic caching
    cache.set('project report', ['file1', 'file2'])
    result = cache.get('project report')
    print(f"Cache hit: {result}")

    # Test LRU eviction
    cache.set('file1', ['data1'])
    cache.set('file2', ['data2'])
    cache.set('file3', ['data3'])  # Cache full
    cache.set('file4', ['data4'])  # Should evict oldest

    stats = cache.get_stats()
    print(f"\nCache stats: {stats}")
    print(f"Cached items: {len(cache.cache)}/{cache.max_size}")

    # Test expiration
    import time
    time.sleep(6)
    expired = cache.cleanup_expired()
    print(f"\nExpired items cleaned up: {expired}")
